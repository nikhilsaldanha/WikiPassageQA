{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "Stemmer=SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(str):\n",
    "    counts = dict()\n",
    "    str=remove_stopwords(str)\n",
    "    words = word_tokenize(str)\n",
    "    #removing stop words\n",
    "    for word in words:\n",
    "        #word = Stemmer.stem(word)\n",
    "        word= wordnet_lemmatizer.lemmatize(word)\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/Learning Material/IR/WikiPassageQA/data/raw/WikiPassageQA/document_passages.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Learning Material/IR/WikiPassageQA/data/raw/extracted_query_data/train_exp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>DocumentName</th>\n",
       "      <th>QID</th>\n",
       "      <th>Question</th>\n",
       "      <th>RelevantPassages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>672</td>\n",
       "      <td>Evangelicalism.html</td>\n",
       "      <td>3086</td>\n",
       "      <td>What is the role of conversionism in Evangelic...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>359</td>\n",
       "      <td>French_Revolution.html</td>\n",
       "      <td>195</td>\n",
       "      <td>How did the assault on the Bastille the first ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359</td>\n",
       "      <td>French_Revolution.html</td>\n",
       "      <td>195</td>\n",
       "      <td>How did the assault on the Bastille the first ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285</td>\n",
       "      <td>Albania.html</td>\n",
       "      <td>557</td>\n",
       "      <td>What is the prehistory of Albania?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>579</td>\n",
       "      <td>Central_Powers.html</td>\n",
       "      <td>1508</td>\n",
       "      <td>What significance did Bulgaria have in the end...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>641</td>\n",
       "      <td>Ancient_Egypt.html</td>\n",
       "      <td>1971</td>\n",
       "      <td>How did conquering of Alexander the great effe...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>641</td>\n",
       "      <td>Ancient_Egypt.html</td>\n",
       "      <td>1971</td>\n",
       "      <td>How did conquering of Alexander the great effe...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>740</td>\n",
       "      <td>Amnesty_International.html</td>\n",
       "      <td>1153</td>\n",
       "      <td>What is Amnesty International?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>740</td>\n",
       "      <td>Amnesty_International.html</td>\n",
       "      <td>1153</td>\n",
       "      <td>What is Amnesty International?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>186</td>\n",
       "      <td>United_States_dollar.html</td>\n",
       "      <td>2944</td>\n",
       "      <td>What is the origin of the dollar sign?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5560 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DocumentID                DocumentName   QID  \\\n",
       "0            672         Evangelicalism.html  3086   \n",
       "1            359      French_Revolution.html   195   \n",
       "2            359      French_Revolution.html   195   \n",
       "3            285                Albania.html   557   \n",
       "4            579         Central_Powers.html  1508   \n",
       "...          ...                         ...   ...   \n",
       "5555         641          Ancient_Egypt.html  1971   \n",
       "5556         641          Ancient_Egypt.html  1971   \n",
       "5557         740  Amnesty_International.html  1153   \n",
       "5558         740  Amnesty_International.html  1153   \n",
       "5559         186   United_States_dollar.html  2944   \n",
       "\n",
       "                                               Question  RelevantPassages  \n",
       "0     What is the role of conversionism in Evangelic...                 4  \n",
       "1     How did the assault on the Bastille the first ...                 1  \n",
       "2     How did the assault on the Bastille the first ...                 2  \n",
       "3                    What is the prehistory of Albania?                 4  \n",
       "4     What significance did Bulgaria have in the end...                14  \n",
       "...                                                 ...               ...  \n",
       "5555  How did conquering of Alexander the great effe...                29  \n",
       "5556  How did conquering of Alexander the great effe...                30  \n",
       "5557                     What is Amnesty International?                 0  \n",
       "5558                     What is Amnesty International?                 9  \n",
       "5559             What is the origin of the dollar sign?                13  \n",
       "\n",
       "[5560 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docid=str(df.iloc[0][0])\n",
    "relp = str(df.iloc[0][4])\n",
    "question=df.iloc[0][3].translate(table).lower()\n",
    "passage=data[docid][relp].translate(table).lower()\n",
    "passage=re.sub(r'\\n', ' ', passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlapping words between question and passage is:- \n",
      "{'conversionism', 'evangelicalism'}\n",
      "Total number of overlapping words: 2\n",
      "Counts of the overlapping words in question and passage:-\n",
      "Q count for the word 'conversionism' is 1\n",
      "P count for the word 'conversionism' is 1\n",
      "Q count for the word 'evangelicalism' is 1\n",
      "P count for the word 'evangelicalism' is 1\n"
     ]
    }
   ],
   "source": [
    "q = word_count(question)\n",
    "p = word_count(passage)\n",
    "setA = set(q)\n",
    "setB = set(p)\n",
    "print(\"The overlapping words between question and passage is:- \")\n",
    "print(setA.intersection(setB))\n",
    "print(\"Total number of overlapping words: \"+str(len(setA.intersection(setB))))\n",
    "print(\"Counts of the overlapping words in question and passage:-\")\n",
    "for item in setA.intersection(setB):\n",
    "    print(\"Q count for the word '\"+ item +\"' is \"+str(q[item]))\n",
    "    print(\"P count for the word '\"+ item +\"' is \"+str(p[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=[]\n",
    "Qcounts=[]\n",
    "Pcounts=[]\n",
    "for i in range(len(df)):\n",
    "    docid=str(df.iloc[i][0])\n",
    "    relp = str(df.iloc[i][4])\n",
    "    question=df.iloc[i][3].translate(table).lower()\n",
    "    passage=data[docid][relp].translate(table).lower()\n",
    "    passage=re.sub(r'\\n', ' ', passage)\n",
    "    q = word_count(question)\n",
    "    p = word_count(passage)\n",
    "    setA = set(q)\n",
    "    setB = set(p)\n",
    "    intersect = setA.intersection(setB)\n",
    "    resQ = {key: q[key] for key in intersect} \n",
    "    resP = {key: p[key] for key in intersect}\n",
    "    Qcounts.append(resQ)\n",
    "    Pcounts.append(resP)\n",
    "    counts.append(len(intersect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.427697841726619, 1.4443473627849468)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = np.array(counts)\n",
    "counts.mean(),counts.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['conversionism', 'evangelicalism'], ['conversionism', 'evangelicalism'])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Qcounts[0]),list(Pcounts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing for the overlapping words how much they occur in the passages on average. \n",
    "means=[]\n",
    "stds=[]\n",
    "for i in range(len(Pcounts)):\n",
    "    if len(list(Pcounts[i]))!=0:\n",
    "        means.append(np.array(list(Pcounts[i].values())).mean())\n",
    "        stds.append(np.array(list(Pcounts[i].values())).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8601640719212873, 1.6717011183184332)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(means).mean(),np.array(means).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9353621364542622, 1.040211955614378)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(stds).mean(),np.array(stds).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_lengths=[]\n",
    "for i in range(len(df)):\n",
    "    docid=str(df.iloc[i][0])\n",
    "    relp = str(df.iloc[i][4])\n",
    "    passage=data[docid][relp].translate(table).lower()\n",
    "    passage=re.sub(r'\\n', ' ', passage)\n",
    "    passage=remove_stopwords(passage)\n",
    "    words = word_tokenize(passage)\n",
    "    passage_lengths.append(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = np.array(list(Pcounts[0].values()))/passage_lengths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_freqs=[]\n",
    "for i in range(len(Pcounts)):\n",
    "    term_freqs.append(np.array(list(Pcounts[i].values()))/passage_lengths[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing for the overlapping words, the term frequencies in the passages on average. \n",
    "means_tf=[]\n",
    "stds_tf=[]\n",
    "for i in range(len(term_freqs)):\n",
    "    if len(list(term_freqs[i]))!=0:\n",
    "        means_tf.append(term_freqs[i].mean())\n",
    "        stds_tf.append(term_freqs[i].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.036780430648495246, 0.020723265726558412)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(means_tf).mean(),np.array(means_tf).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.011620920957570592, 0.012404180835918452)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(stds_tf).mean(),np.array(stds_tf).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpassages=[]\n",
    "for i in data.keys():\n",
    "    for j in data[i].keys():\n",
    "        allpassages.append(data[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dict()      \n",
    "for dicts in Pcounts:\n",
    "    for word in list(dicts.keys()):        \n",
    "        count=0\n",
    "        for passages in allpassages:\n",
    "            if word in passages:\n",
    "                count+=1\n",
    "                continue\n",
    "        counts[word]=count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[\"evangelicalism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('DocumentFreq.pickle', 'wb') as handle:\n",
    "    pickle.dump(counts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "evangelicalismidf=np.log(50612/(counts[\"evangelicalism\"]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.138263093582144"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf[0]*evangelicalismidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01639344, 0.01639344])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freqs[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "termfreq_idf=[]\n",
    "for i,j in zip(term_freqs,Pcounts):\n",
    "    templ=[]\n",
    "    for k,l in zip(i,j.keys()):\n",
    "        templ.append(k*np.log(50612/(counts[l]+1)))\n",
    "        \n",
    "    termfreq_idf.append(np.array(templ))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16620978, 0.13826309])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termfreq_idf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing for the overlapping words how much they occur with respect to term freq_idf in the passages on average. \n",
    "means_tf_idf=[]\n",
    "stds_tf_idf=[]\n",
    "for i in range(len(termfreq_idf)):\n",
    "    if len(list(termfreq_idf[i]))!=0:\n",
    "        means_tf_idf.append(termfreq_idf[i].mean())\n",
    "        stds_tf_idf.append(termfreq_idf[i].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22857354643418254, 0.16851839428618678)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(means_tf_idf).mean(),np.array(means_tf_idf).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0927228723529515, 0.10314854542203701)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(stds_tf_idf).mean(),np.array(stds_tf_idf).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
